{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import ast\n",
        "import numpy as np\n",
        "import json\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ot7iZput-x",
        "outputId": "9b06c335-10b8-40b3-ced8-a78080d73009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "rEMxhoNMvA05"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsmLhViyu9Rn",
        "outputId": "8f0db43e-7146-4c12-8122-6064c4d0f711"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Function"
      ],
      "metadata": {
        "id": "tPIRypk7uj6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"slang_words.txt\", \"r\") as slang_file:\n",
        "  slang_content = slang_file.read()\n",
        "  slang_words = ast.literal_eval(slang_content)"
      ],
      "metadata": {
        "id": "h67rEp0SYn60"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EKoeFyH0uSqm"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "  text = re.sub('-',' ',text)\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "  return text\n",
        "\n",
        "def case_folding(text):\n",
        "  text = text.lower()\n",
        "  return text\n",
        "\n",
        "def tokenizingText(text):\n",
        "  text = word_tokenize(text)\n",
        "  return text\n",
        "\n",
        "def slang_word(text):\n",
        "  filtered = []\n",
        "  for txt in text:\n",
        "    if txt not in slang_words.keys():\n",
        "      filtered.append(txt)\n",
        "    if txt in slang_words.keys():\n",
        "      x = txt.replace(txt, slang_words[txt])\n",
        "      filtered.append(x)\n",
        "  text = filtered\n",
        "  return text\n",
        "\n",
        "def stemmingText(text):\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  text = [stemmer.stem(word) for word in text]\n",
        "  return text\n",
        "\n",
        "def toSentence(list_words):\n",
        "  sentence = ' '.join(word for word in list_words)\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(list):\n",
        "  cleaned_text = [remove_punctuation(x) for x in list]\n",
        "  cleaned_text = [case_folding(x) for x in cleaned_text]\n",
        "  tokenized_text = [tokenizingText(x) for x in cleaned_text]\n",
        "  standarized_text = [slang_word(x) for x in tokenized_text]\n",
        "  stemmed_text = [stemmingText(x) for x in standarized_text]\n",
        "  preprocessed_text = [toSentence(x) for x in tokenized_text]\n",
        "\n",
        "  return preprocessed_text"
      ],
      "metadata": {
        "id": "_SVDN07_vZXS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing Function"
      ],
      "metadata": {
        "id": "VhrxBgXs7ZFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "with open('word_index.json') as json_word_index:\n",
        "  word_index = json.load(json_word_index)\n",
        "tokenizer.word_index = word_index"
      ],
      "metadata": {
        "id": "_qDT0sExwoYf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_for_sequences(preprocessed_text):\n",
        "  sequences = tokenizer.texts_to_sequences(preprocessed_text)\n",
        "  padded_sequences = pad_sequences(sequences, padding='post', maxlen=150)\n",
        "\n",
        "  return padded_sequences"
      ],
      "metadata": {
        "id": "nlthNO95w849"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and Prediction"
      ],
      "metadata": {
        "id": "esh1OMdc7hNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('lstm_model.h5')"
      ],
      "metadata": {
        "id": "azwTC-ESyUmq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_to_predict(text):\n",
        "  preprocessed_text = data_preprocessing(text)\n",
        "  padded_sequences = token_for_sequences(preprocessed_text)\n",
        "  result = model.predict(padded_sequences)\n",
        "  weight = 0\n",
        "  denominator = 0\n",
        "  for value in result:\n",
        "    weight +=1\n",
        "    value *= weight\n",
        "    denominator+=weight\n",
        "  avg_result = np.sum(result)/denominator\n",
        "  return avg_result"
      ],
      "metadata": {
        "id": "R7QFXjeUywdK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "6A25EPyCeg9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_to_predict(['Sangat agresif saat melihat anjing lain; Saya takut berantem dengan anjing lain.',\n",
        "                       'Ketika aku memanggilnya untuk makan, Henry akan datang dengan cepat, mengibaskan ekornya. Dia akan duduk dengan sabar menunggu sinyal dariku, dan kemudian menikmati makanannya dengan lahap.',\n",
        "                       'Anjingku tidak nafsu makan, meskipun dia masih sering bermain dengan teman-temannya',\n",
        "                       'anjingku benar-benar malas banget, dia cuma tidur-tiduran tidak karuan. AKu juga sudah mencoba membawanya berkeliling, tapi dia kelihatan gak semangat.',\n",
        "                       'Hari ini anjingku tidak lagi kencing sembarangan dan saya senang sekali',\n",
        "                       'Ia selalu nyenyak saat majikannya, Rani, memberinya tempat tidur yang nyaman, seperti kasur, bantal, atau selimut.',\n",
        "                       'Gani adalah anjing yang suka bersosialisasi. Gani adalah anjing yang ramah dan asertif. Ia selalu senang saat majikannya, Rani, membawanya ke tempat-tempat ramai, seperti pasar, mall, atau taman.',\n",
        "                       ])"
      ],
      "metadata": {
        "id": "wWQW3Ceazo16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d49c097-4e22-4565-f665-0727da6f4f31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 695ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5429657186780658"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}